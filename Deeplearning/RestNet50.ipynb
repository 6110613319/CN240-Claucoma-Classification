{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c7580b-e5e0-44de-bccc-d6df065ff43b",
   "metadata": {},
   "source": [
    "# Create ResNet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "245fbc2b-b47b-4053-bab4-b5fe8947a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning on already trained ResNet50. Compile process.\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "categories = 3\n",
    "\n",
    "TRAIN_DIR = 'Data_Train/'\n",
    "TEST_DIR = 'Data_Test/'\n",
    "TARGETS = [\"glaucoma\", \"normal\", \"other\"]\n",
    "\n",
    "model = ResNet50(include_top = False, weights = 'imagenet',input_shape=(256,256,3), classifier_activation='softmax',pooling='max')\n",
    "\n",
    "# The fully connected top layer of ResNet50 is not to added in this model\n",
    "flattened = Flatten()(model.output)\n",
    "# All inputs and outputs are connected to neurons (Dense Layers)\n",
    "# ReLu activation can be used here. Difference --?\n",
    "fc1 = Dense(3, activation='softmax', name=\"AddedDense2\")(flattened)\n",
    "\n",
    "full_model = Model(inputs=model.input, outputs=fc1)\n",
    "full_model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2bfd826-3959-4fc5-8053-f9a63f5268d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e9f6bdf-c5af-45f0-9d9b-779ac92c2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.compile(adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cae2050-f6ec-4318-991d-ce2723c16f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool (GlobalMaxPooling2D)   (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "AddedDense2 (Dense)             (None, 3)            6147        flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,593,859\n",
      "Trainable params: 23,540,739\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbb9f039-2dd7-40af-a2a3-f68f5ee4cafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8718 files belonging to 3 classes.\n",
      "Using 6975 files for training.\n",
      "Found 8718 files belonging to 3 classes.\n",
      "Using 1743 files for validation.\n",
      "Found 2184 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    batch_size=8,\n",
    "    image_size=(256, 256),\n",
    "    label_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "validate_data = image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    batch_size=8,\n",
    "    image_size=(256, 256),\n",
    "    label_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    ")\n",
    "\n",
    "test_data = image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    batch_size=8,\n",
    "    image_size=(256, 256),\n",
    "    label_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3be3d048-b812-4eaf-bd9a-172b4bf9272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'Model/resnet50_best.h5'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854ec59-4cd4-4bce-a7e3-6dcad0441455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "872/872 [==============================] - 327s 368ms/step - loss: 2.4260 - accuracy: 0.7029 - val_loss: 1.2899 - val_accuracy: 0.5399\n",
      "Epoch 2/20\n",
      "872/872 [==============================] - 298s 341ms/step - loss: 0.8249 - accuracy: 0.8095 - val_loss: 0.4967 - val_accuracy: 0.7831\n",
      "Epoch 3/20\n",
      "872/872 [==============================] - 298s 341ms/step - loss: 0.7997 - accuracy: 0.8120 - val_loss: 3.8539 - val_accuracy: 0.5324\n",
      "Epoch 4/20\n",
      "872/872 [==============================] - 296s 339ms/step - loss: 0.7285 - accuracy: 0.7963 - val_loss: 5.2376 - val_accuracy: 0.4940\n",
      "Epoch 5/20\n",
      "872/872 [==============================] - 298s 341ms/step - loss: 0.4985 - accuracy: 0.8360 - val_loss: 2.2318 - val_accuracy: 0.7183\n",
      "Epoch 6/20\n",
      "872/872 [==============================] - 297s 341ms/step - loss: 0.4546 - accuracy: 0.8670 - val_loss: 0.7414 - val_accuracy: 0.7774\n",
      "Epoch 7/20\n",
      "872/872 [==============================] - 298s 342ms/step - loss: 0.3178 - accuracy: 0.8892 - val_loss: 3.3059 - val_accuracy: 0.6845\n",
      "Epoch 8/20\n",
      "872/872 [==============================] - 296s 340ms/step - loss: 0.2595 - accuracy: 0.9080 - val_loss: 1.4315 - val_accuracy: 0.7476\n",
      "Epoch 9/20\n",
      "872/872 [==============================] - 297s 341ms/step - loss: 0.1928 - accuracy: 0.9257 - val_loss: 1.2514 - val_accuracy: 0.7527\n",
      "Epoch 10/20\n",
      "872/872 [==============================] - 298s 342ms/step - loss: 0.2168 - accuracy: 0.9158 - val_loss: 1.4909 - val_accuracy: 0.5978\n",
      "Epoch 11/20\n",
      "872/872 [==============================] - 297s 341ms/step - loss: 0.1828 - accuracy: 0.9336 - val_loss: 0.9202 - val_accuracy: 0.7717\n",
      "Epoch 12/20\n",
      "872/872 [==============================] - 297s 340ms/step - loss: 0.1707 - accuracy: 0.9356 - val_loss: 0.3305 - val_accuracy: 0.8732\n",
      "Epoch 13/20\n",
      "872/872 [==============================] - 296s 340ms/step - loss: 0.1492 - accuracy: 0.9406 - val_loss: 1.0388 - val_accuracy: 0.7826\n",
      "Epoch 14/20\n",
      "872/872 [==============================] - 297s 341ms/step - loss: 0.1210 - accuracy: 0.9515 - val_loss: 1.8095 - val_accuracy: 0.6931\n",
      "Epoch 15/20\n",
      "872/872 [==============================] - 297s 341ms/step - loss: 0.1701 - accuracy: 0.9359 - val_loss: 0.5633 - val_accuracy: 0.8600\n",
      "Epoch 16/20\n",
      "872/872 [==============================] - 300s 344ms/step - loss: 0.1375 - accuracy: 0.9468 - val_loss: 3.5757 - val_accuracy: 0.4337\n",
      "Epoch 17/20\n",
      "872/872 [==============================] - 296s 339ms/step - loss: 0.1140 - accuracy: 0.9567 - val_loss: 1.2863 - val_accuracy: 0.6523\n",
      "Epoch 18/20\n",
      "872/872 [==============================] - 296s 340ms/step - loss: 0.1184 - accuracy: 0.9548 - val_loss: 0.7185 - val_accuracy: 0.8451\n",
      "Epoch 19/20\n",
      "415/872 [=============>................] - ETA: 2:25 - loss: 0.1145 - accuracy: 0.9578"
     ]
    }
   ],
   "source": [
    "model_fitting = full_model.fit_generator(\n",
    "        train_data,\n",
    "        epochs = 20,\n",
    "        validation_data=validate_data,\n",
    "        callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "412f65dc-9c7f-4b5a-af9b-3f29a7e76a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "full_model.save('model_20ep.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b3176fa-b4ff-4425-89f7-0eb85c60f94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../muteluh-fundus/model.h5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "copyfile('model_20ep.h5', '../muteluh-fundus/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8af5095-9c9b-4121-a6b0-e5bc43c4a3f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b7c5d64e3a9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'resnet.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model_fitting.history['accuracy'], label='accuracy')\n",
    "plt.plot(model_fitting.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('resnet.jpg')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_data, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ff6c120-e17e-4df1-8644-f3522414892e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig('resnet.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3712758-4c19-4de7-bff4-8d40a09a0955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "545/545 [==============================] - 315s 576ms/step - loss: 0.2469 - accuracy: 0.9288 - val_loss: 0.3880 - val_accuracy: 0.8316\n",
      "Epoch 2/10\n",
      "545/545 [==============================] - 480s 880ms/step - loss: 0.2198 - accuracy: 0.9412 - val_loss: 0.2884 - val_accuracy: 0.9013\n",
      "Epoch 3/10\n",
      "545/545 [==============================] - 419s 766ms/step - loss: 0.2158 - accuracy: 0.9321 - val_loss: 3.1126 - val_accuracy: 0.4277\n",
      "Epoch 4/10\n",
      "545/545 [==============================] - 342s 627ms/step - loss: 0.1747 - accuracy: 0.9474 - val_loss: 4.0645 - val_accuracy: 0.6994\n",
      "Epoch 5/10\n",
      "545/545 [==============================] - 329s 604ms/step - loss: 0.1816 - accuracy: 0.9460 - val_loss: 7.2918 - val_accuracy: 0.3676\n",
      "Epoch 6/10\n",
      "545/545 [==============================] - 559s 1s/step - loss: 0.1453 - accuracy: 0.9496 - val_loss: 0.1719 - val_accuracy: 0.9371\n",
      "Epoch 7/10\n",
      "545/545 [==============================] - 376s 690ms/step - loss: 0.1699 - accuracy: 0.9475 - val_loss: 0.2278 - val_accuracy: 0.9133\n",
      "Epoch 8/10\n",
      "545/545 [==============================] - 339s 622ms/step - loss: 0.1578 - accuracy: 0.9463 - val_loss: 1.4171 - val_accuracy: 0.7187\n",
      "Epoch 9/10\n",
      "545/545 [==============================] - 339s 622ms/step - loss: 0.1073 - accuracy: 0.9595 - val_loss: 0.5893 - val_accuracy: 0.8490\n",
      "Epoch 10/10\n",
      "545/545 [==============================] - 338s 620ms/step - loss: 0.1286 - accuracy: 0.9578 - val_loss: 6.4887 - val_accuracy: 0.6622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b439e4dfd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.fit_generator(\n",
    "        train_data,\n",
    "        epochs = 10,\n",
    "        validation_data=validate_data,\n",
    "        callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ad353d2-f0e1-4bcd-915d-82aa19433a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "full_model.save('resnet50_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd4f6dc6-51bc-405b-971d-0281e884cb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F690906A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "\n",
    "img = cv2.imread('Data_Train/class_normal/normal_10_rotated_127.jpg')\n",
    "class_names = [\"glaucoma\", \"normal\", \"other\"]\n",
    "model = load_model('resnet50_test.h5')\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "img = cv2.resize(img,(256,256))\n",
    "img = np.reshape(img,[1,256,256,3])\n",
    "predictions = model.predict(img)\n",
    "argmax = np.argmax(predictions > 0.5).astype(\"int32\")\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(argmax)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5b8ec6e-7c83-447f-bcc5-0d45f9de6000",
   "metadata": {},
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71576369-2b94-4553-bff9-7a82bf23ab67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         4.57748    0.         ... 4.8335667  0.\n",
      "    0.        ]\n",
      "   [0.         3.5334406  0.         ... 0.45722917 0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d6cd74d-e4f9-433b-a47f-81536ebf9cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "436/436 [==============================] - 249s 572ms/step - loss: 0.1742 - accuracy: 0.9627 - val_loss: 0.0969 - val_accuracy: 0.9662\n",
      "Epoch 2/70\n",
      "436/436 [==============================] - 251s 576ms/step - loss: 0.1577 - accuracy: 0.9690 - val_loss: 0.1178 - val_accuracy: 0.9644\n",
      "Epoch 3/70\n",
      "436/436 [==============================] - 251s 576ms/step - loss: 0.3016 - accuracy: 0.9619 - val_loss: 0.1080 - val_accuracy: 0.9639\n",
      "Epoch 4/70\n",
      "436/436 [==============================] - 248s 569ms/step - loss: 0.1637 - accuracy: 0.9730 - val_loss: 0.0801 - val_accuracy: 0.9690\n",
      "Epoch 5/70\n",
      "436/436 [==============================] - 248s 568ms/step - loss: 0.1253 - accuracy: 0.9685 - val_loss: 0.1033 - val_accuracy: 0.9662\n",
      "Epoch 6/70\n",
      "436/436 [==============================] - 5228s 12s/step - loss: 0.2389 - accuracy: 0.9601 - val_loss: 0.1290 - val_accuracy: 0.9673\n",
      "Epoch 7/70\n",
      "436/436 [==============================] - 253s 581ms/step - loss: 0.1889 - accuracy: 0.9670 - val_loss: 0.5507 - val_accuracy: 0.8571\n",
      "Epoch 8/70\n",
      "436/436 [==============================] - 253s 579ms/step - loss: 0.2786 - accuracy: 0.9633 - val_loss: 0.2640 - val_accuracy: 0.9225\n",
      "Epoch 9/70\n",
      "436/436 [==============================] - 255s 584ms/step - loss: 0.1990 - accuracy: 0.9679 - val_loss: 0.1488 - val_accuracy: 0.9495\n",
      "Epoch 10/70\n",
      "436/436 [==============================] - 499s 1s/step - loss: 0.1255 - accuracy: 0.9748 - val_loss: 0.1456 - val_accuracy: 0.9610\n",
      "Epoch 11/70\n",
      "436/436 [==============================] - 251s 575ms/step - loss: 0.0929 - accuracy: 0.9791 - val_loss: 0.0999 - val_accuracy: 0.9719\n",
      "Epoch 12/70\n",
      "436/436 [==============================] - 251s 575ms/step - loss: 0.1601 - accuracy: 0.9703 - val_loss: 0.1310 - val_accuracy: 0.9535\n",
      "Epoch 13/70\n",
      "436/436 [==============================] - 252s 578ms/step - loss: 1.1468 - accuracy: 0.9346 - val_loss: 0.2542 - val_accuracy: 0.9346\n",
      "Epoch 14/70\n",
      "436/436 [==============================] - 252s 578ms/step - loss: 0.5715 - accuracy: 0.9517 - val_loss: 0.2106 - val_accuracy: 0.9300\n",
      "Epoch 15/70\n",
      "436/436 [==============================] - 252s 577ms/step - loss: 0.2410 - accuracy: 0.9673 - val_loss: 0.1531 - val_accuracy: 0.9541\n",
      "Epoch 16/70\n",
      "436/436 [==============================] - 251s 576ms/step - loss: 0.1375 - accuracy: 0.9761 - val_loss: 0.1664 - val_accuracy: 0.9610\n",
      "Epoch 17/70\n",
      "436/436 [==============================] - 253s 579ms/step - loss: 0.0750 - accuracy: 0.9818 - val_loss: 0.0778 - val_accuracy: 0.9782\n",
      "Epoch 18/70\n",
      "436/436 [==============================] - 252s 579ms/step - loss: 0.0534 - accuracy: 0.9837 - val_loss: 0.1458 - val_accuracy: 0.9644\n",
      "Epoch 19/70\n",
      "436/436 [==============================] - 251s 577ms/step - loss: 0.0815 - accuracy: 0.9799 - val_loss: 0.1551 - val_accuracy: 0.9690\n",
      "Epoch 20/70\n",
      "436/436 [==============================] - 250s 573ms/step - loss: 0.1998 - accuracy: 0.9784 - val_loss: 0.0956 - val_accuracy: 0.9725\n",
      "Epoch 21/70\n",
      " 30/436 [=>............................] - ETA: 3:36 - loss: 0.0359 - accuracy: 0.9854"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-052a7c30b4cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m full_model.fit_generator(train_data,\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         callbacks=[checkpoint])\n",
      "\u001b[1;32mc:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1941\u001b[0m                   \u001b[1;34m'will be removed in a future version. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1942\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[1;32m-> 1943\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1944\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1945\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_model.fit_generator(train_data,\n",
    "        epochs = 70,\n",
    "        validation_data=validate_data,\n",
    "        callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08796f2d-c59f-47fc-987b-75007ff4f877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "full_model.save('resnet50_50ep.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1064ec7-a910-4565-b24a-353e4fdb4aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    }
   ],
   "source": [
    "copy('resnet50_50ep.h5','../../muteluh-fundus/resnet50_50ep.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46d5c880-4663-42e6-8d6f-c2325b765e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../muteluh-fundus/resnet50_50ep.h5'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "copyfile('resnet50_50ep.h5', '../../muteluh-fundus/resnet50_50ep.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4c47b-4b64-49ec-b9ec-660e488d87b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83f77795-f55b-41b4-88d2-f4294877db04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "\n",
    "img = cv2.imread('Data_Train/class_other/other_10_rotated_1.jpg')\n",
    "class_names = [\"glaucoma\", \"normal\", \"other\"]\n",
    "model = load_model('resnet50_50ep.h5')\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "img = cv2.resize(img,(256,256))\n",
    "img = np.reshape(img,[1,256,256,3])\n",
    "predictions = model.predict(img)\n",
    "print(predictions)\n",
    "argmax = np.argmax(predictions)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd7d6f23-a326-43d0-8f4e-bdd3029fe20b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit_generator() got an unexpected keyword argument 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-19b3d3daf18b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m full_model.fit_generator(\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit_generator() got an unexpected keyword argument 'batch_size'"
     ]
    }
   ],
   "source": [
    "full_model.fit_generator(\n",
    "        train_data,\n",
    "        epochs = 10,\n",
    "        validation_data=validate_data,\n",
    "        callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadb06e7-7320-4092-8a7b-863596926f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
